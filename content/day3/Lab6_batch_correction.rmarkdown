# Lab 6: Batch correction

::: {.callout-note icon='true'}

## Notes

The estimated time for this lab is around 1h30.

:::

::: {.callout-tip icon='true'}

## Aims

- Process pancreas scRNAseq datasets from different technologies. 
- Merge the datasets and analyse them without batch correction.
- Use Seurat to perform batch correction using canonical correlation analysis (CCA) and mutual nearest neighbors (MNN).
- Use LIGER to perform batch correction using integrative non-negative matrix factorization.

:::


```{r eval = TRUE, echo = FALSE, warning = FALSE, error = FALSE, comment = FALSE, message = FALSE}
knitr::opts_chunk$set(eval = FALSE)
```


In this lab, we will look at different single cell RNA-seq datasets collected from pancreatic islets. We will look at how different batch correction methods affect our data analysis.

## Read in pancreas expression matrices

Four different datasets are provided in the `~/Share/batch_correction/` directory. These datasets were collected using different single cell RNA-seq technologies.

::: {.callout-question .icon .callout-note}

Import the four datasets into R. What is the size and sparsity of each dataset? 

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, read2, filename = "R"}
celseq.data <- read.table("~/Share/batch_correction/pancreas_multi_celseq_expression_matrix.txt.gz")
celseq2.data <- read.table("~/Share/batch_correction/pancreas_multi_celseq2_expression_matrix.txt.gz")
fluidigmc1.data <- read.table("~/Share/batch_correction/pancreas_multi_fluidigmc1_expression_matrix.txt.gz")
smartseq2.data <- read.table("~/Share/batch_correction/pancreas_multi_smartseq2_expression_matrix.txt.gz")
```


Coerce each dataset to a sparse matrix for efficiency.


```{r eval = TRUE, read, filename = "R"}
# Convert to sparse matrices for efficiency
library(Matrix)
celseq.data <- as(as.matrix(celseq.data), "dgCMatrix")
celseq2.data <- as(as.matrix(celseq2.data), "dgCMatrix")
fluidigmc1.data <- as(as.matrix(fluidigmc1.data), "dgCMatrix")
smartseq2.data <- as(as.matrix(smartseq2.data), "dgCMatrix")
```


:::

:::

## Analyze each pancreas dataset without batch correction

We will first analyze each dataset separately to see if there are any differences between the datasets.

::: {.callout-question .icon .callout-note}

What is the size of each single cell RNA-seq dataset? 

Briefly describe the technology used to collect each dataset.

Which datasets do you expect to be different and which do you expect to be similar?

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, prepare_seurat, filename = "R"}
dim(celseq.data)
dim(celseq2.data)
dim(fluidigmc1.data)
dim(smartseq2.data)
```


:::

:::

::: {.callout-question .icon .callout-note}

Create a Seurat object for each dataset, and look at the distributions of number of genes per cell.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, coerce_seurat, filename = "R"}
library(Seurat)

# CEL-Seq (https://www.cell.com/cell-reports/fulltext/S2211-1247(12)00228-8)
celseq <- CreateSeuratObject(counts = celseq.data)
VlnPlot(celseq, "nFeature_RNA")

# CEL-Seq2 https://www.cell.com/molecular-cell/fulltext/S1097-2765(09)00641-8
celseq2 <- CreateSeuratObject(counts = celseq2.data)
VlnPlot(celseq2, "nFeature_RNA")

# Fluidigm C1
fluidigmc1 <- CreateSeuratObject(counts = fluidigmc1.data)
VlnPlot(fluidigmc1, "nFeature_RNA")

# SMART-Seq2
smartseq2 <- CreateSeuratObject(counts = smartseq2.data)
VlnPlot(smartseq2, "nFeature_RNA")
```


:::

:::

Now we will subset the data to remove cells with low gene counts and normalize the data.

::: {.callout-question .icon .callout-note}

Subset the data to remove cells with: 

- fewer than 1750 genes for CEL-Seq; 
- fewer than 2500 genes for CEL-Seq2; 
- fewer than 2500 genes for SMART-Seq2.

::: {.callout-answer .icon .callout-note collapse=true}

```{r eval = TRUE, subset_seurat, filename = "R"}
celseq <- subset(celseq, subset = nFeature_RNA > 1750)
VlnPlot(celseq, "nFeature_RNA")

celseq2 <- subset(celseq2, subset = nFeature_RNA > 2500)
VlnPlot(celseq2, "nFeature_RNA")

smartseq2 <- subset(smartseq2, subset = nFeature_RNA > 2500)
VlnPlot(smartseq2, "nFeature_RNA")
```


:::

:::

Now we will normalize the data and identify variable genes. The procedure is the same for all datasets.


::: {.callout-question .icon .callout-note}

Normalize the data with `LogNormalize` method, and identify the 2000 most variable genes for each dataset, using the `vst` approach.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, prepare_seurat2, filename = "R"}
celseq <- NormalizeData(celseq, normalization.method = "LogNormalize", scale.factor = 10000)
celseq <- FindVariableFeatures(celseq, selection.method = "vst", nfeatures = 2000)
celseq <- ScaleData(celseq)
celseq[["tech"]] <- "celseq"
celseq

celseq2 <- NormalizeData(celseq2, normalization.method = "LogNormalize", scale.factor = 10000)
celseq2 <- FindVariableFeatures(celseq2, selection.method = "vst", nfeatures = 2000)
celseq2 <- ScaleData(celseq2)
celseq2[["tech"]] <- "celseq2"
celseq2

fluidigmc1 <- NormalizeData(fluidigmc1, normalization.method = "LogNormalize", scale.factor = 10000)
fluidigmc1 <- FindVariableFeatures(fluidigmc1, selection.method = "vst", nfeatures = 2000)
fluidigmc1 <- ScaleData(fluidigmc1)
fluidigmc1[["tech"]] <- "fluidigmc1"
fluidigmc1

smartseq2 <- NormalizeData(smartseq2, normalization.method = "LogNormalize", scale.factor = 10000)
smartseq2 <- FindVariableFeatures(smartseq2, selection.method = "vst", nfeatures = 2000)
smartseq2 <- ScaleData(smartseq2)
smartseq2[["tech"]] <- "smartseq2"
smartseq2
```


:::

:::

## Cluster pancreatic datasets without batch correction

We will first merge all the cells from the four different experiments together, and cluster all the pancreatic islet datasets to see whether there is a batch effect.

::: {.callout-question .icon .callout-note}

Merge the datasets into a single Seurat object.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, no_batch_correction, filename = "R"}
# Merge Seurat objects. Original sample identities are stored in gcdata[["tech"]].
# Cell names will now have the format tech_cellID (smartseq2_cell1...)
add.cell.ids <- c("celseq", "celseq2", "fluidigmc1", "smartseq2")
gcdata <- merge(x = celseq, y = list(celseq2, fluidigmc1, smartseq2), add.cell.ids = add.cell.ids, merge.data = FALSE)
Idents(gcdata) <- "tech"  # use identity based on sample identity
gcdata
VlnPlot(gcdata, "nFeature_RNA", group.by = "tech")
```


:::

:::

After merging, we will perform again the normalization, variable gene selection, and scaling.

::: {.callout-question .icon .callout-note}

What is the difference between `SelectIntegrationFeatures` and `FindVariableFeatures` in Seurat?

Run `NormalizeData`, `SelectIntegrationFeatures`, and `ScaleData` on the merged dataset. 

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, no_batch_correction2, filename = "R"}
gcdata <- NormalizeData(gcdata, normalization.method = "LogNormalize", scale.factor = 10000)
var.genes <- SelectIntegrationFeatures(
  list(celseq, celseq2, fluidigmc1, smartseq2), 
  nfeatures = 2000, 
  verbose = TRUE, 
  fvf.nfeatures = 2000, 
  selection.method = "vst"
)
VariableFeatures(gcdata) <- var.genes
gcdata <- ScaleData(gcdata, features = VariableFeatures(gcdata))
```


:::

:::

Now that data is merged, normalized, and scaled, we will perform principal component analysis (PCA) and visualize the data.

::: {.callout-question .icon .callout-note}

Do PCA on data including only the variable genes.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, no_batch_correction3, filename = "R"}
gcdata <- RunPCA(gcdata, features = VariableFeatures(gcdata), npcs = 40, ndims.print = 1:5, nfeatures.print = 5)
```


:::

Color the PCA biplot by the scRNA-seq technology.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, no_batch_correction4, filename = "R"}
DimPlot(gcdata, reduction = "pca", dims = c(1, 2), group.by = "tech")
```


:::

:::

Now we will cluster the cells and visualize the clusters in reduced dimensional space.

::: {.callout-question .icon .callout-note}

- Find the k=20 nearest neighbors for each cell in the PCA space, using the first 20 principal components.
- Cluster the cells.
- Perform UMAP embedding and visualize clustering results in 2D. 

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, no_batch_correction5, filename = "R"}
# Cluster the cells using the first twenty principal components.
gcdata <- FindNeighbors(gcdata, reduction = "pca", dims = 1:20, k.param = 20)
gcdata <- FindClusters(gcdata, resolution = 0.8, algorithm = 1, random.seed = 100)

# Create a UMAP visualization. 
gcdata <- RunUMAP(gcdata, dims = 1:20, reduction = "pca", n.neighbors = 15, min.dist = 0.5, spread = 1, metric = "euclidean", seed.use = 1)  

# Visualize the Leiden clustering and the batches on the UMAP. 
# Remember, the clustering is stored in @meta.data in column seurat_clusters and the technology is
# stored in the column tech. Remember you can also use DimPlot
DimPlot(gcdata, reduction = "umap", group.by = "seurat_clusters")
DimPlot(gcdata, reduction = "umap", group.by = "tech")
```


:::

Are you surprised by the results? Compare to your expectations from the PC biplot of PC1 vs PC2.

What explains these results?

:::

We can assess the quality of the clustering by calculating the adjusted rand index (ARI) between the technology and the cluster labels.
This goes between 0 (completely dissimilar clustering) to 1 (identical clustering). The adjustment corrects for chance grouping between cluster elements.



```{r eval = TRUE, no_batch_correction6, filename = "R"}
library(fossil)
ari <- dplyr::select(gcdata[[]], tech, seurat_clusters)
ari$tech <- plyr::mapvalues(ari$tech, from = c("celseq", "celseq2", "fluidigmc1", "smartseq2"), to = c(0, 1, 2, 3))
adj.rand.index(as.numeric(ari$tech), as.numeric(ari$seurat_clusters))
```


### Batch correction: canonical correlation analysis (CCA)+ mutual nearest neighbors (MNN) using Seurat v3

We will now use Seurat to see to what extent it can remove potential batch effects.

The first piece of code will identify variable genes that are highly variable in at least 2/4 datasets. We will use these variable genes in our batch correction.

Why would we implement such a requirement?

::: {.callout-question .icon .callout-note}

The integration workflow in Seurat requires the identification of variable genes that are variable across most samples. Use the `FindIntegrationAnchors` function to identify anchors on the 4 pancreatic islet datasets, commonly shared variable genes across samples, and integrate samples.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, batchcorrect_Seurat, filename = "R"}
ob.list <- list(celseq, celseq2, fluidigmc1, smartseq2)
gcdata.anchors <- FindIntegrationAnchors(object.list = ob.list, anchor.features = 2000, dims = 1:30)
gcdata <- IntegrateData(anchorset = gcdata.anchors, dims = 1:30)
DefaultAssay(gcdata) <- "integrated"
```


:::

:::

Now that the integration anchors have been used to integrate multiple datasets, we will perform the same analysis as before.

::: {.callout-question .icon .callout-note}

- Normalize the integrated data with `LogNormalize` method.
- Identify the 2000 most variable genes for the integrated dataset, using the `vst` approach.
- Scale the data.
- Perform PCA on data including only the variable genes.
- Cluster the cells.
- Perform UMAP embedding and visualize clustering results in 2D.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, batchcorrect_Seurat2, filename = "R"}
# Run the standard workflow for visualization and clustering.
gcdata <- ScaleData(gcdata, do.center = TRUE, do.scale = FALSE)
gcdata <- FindVariableFeatures(gcdata)
gcdata <- RunPCA(gcdata, npcs = 40, ndims.print = 1:5, nfeatures.print = 5)
DimPlot(gcdata, dims = c(1, 2), reduction = "pca", split.by = "tech")

# Clustering
gcdata <- FindNeighbors(gcdata, reduction = "pca", dims = 1:20, k.param = 20)
gcdata <- FindClusters(gcdata, resolution = 0.8, algorithm = 1, random.seed = 100)

# UMAP
gcdata <- RunUMAP(gcdata, dims = 1:30, reduction = "pca", n.neighbors = 15, min.dist = 0.5, spread = 1, metric = "euclidean", seed.use = 1)  

# After data integration, use the original expression data in all visualization and DE tests.
# The integrated data must not be used in DE tests as it violates assumptions of independence in DE tests!
DefaultAssay(gcdata) <- "RNA"  

# Visualize the Louvain clustering and the batches on the UMAP. 
p1 <- DimPlot(gcdata, reduction = "umap", group.by = "seurat_clusters")
p2 <- DimPlot(gcdata, reduction = "umap", group.by = "tech")
p1 + p2
```


:::

:::

Let's look again to see how the adjusted rand index changed compared to using no batch correction.


```{r eval = TRUE, batchcorrect_Seurat3, filename = "R"}
ari <- dplyr::select(gcdata[[]], tech, seurat_clusters)
ari$tech <- plyr::mapvalues(ari$tech, from = c("celseq", "celseq2", "fluidigmc1", "smartseq2"), to = c(0, 1, 2, 3))
adj.rand.index(as.numeric(ari$tech), as.numeric(ari$seurat_clusters))
```


### Differential gene expression and visualization

We can also identify conserved marker genes across the batches. Differential gene expression is done across each batch, and the p-values are combined. (requires `metap` package installation).


```{r eval = TRUE, batchcorrect_Seurat3b, filename = "R"}
gcdata <- JoinLayers(gcdata)
markers <- FindConservedMarkers(gcdata, ident.1 = 0, grouping.var = "tech", assay = "RNA", print.bar = TRUE)
head(markers)
```


::: {.callout-question .icon .callout-note}

Visualize the expression of the first 5 marker genes on UMAP across the different batches using `DoHeatmap`.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = TRUE, batchcorrect_Seurat4, filename = "R"}
gcdata <- ScaleData(gcdata, features = rownames(gcdata), do.center = T, do.scale = F)
DoHeatmap(gcdata, features = rownames(markers)[1:5], group.by = "tech", disp.max = 3)
```


:::

Check the expression of some known marker genes for pancreatic cells (see the [Human pancreas cell atlas](https://www.cell.com/cell-systems/pdfExtended/S2405-4712(16)30292-7)).


```{r eval = TRUE, batchcorrect_Seurat5, filename = "R"}
genes <- c("GCG", "INS", "SST", "PPY", "PRSS1", "KRT19", "PECAM1", "COL1A1")
FeaturePlot(gcdata, genes, ncol = 4)
```


:::

### Batch correction: integrative non-negative matrix factorization (NMF) using LIGER

Here we use integrative non-negative matrix factorization to see to what extent it can remove potential batch effects.

The important parameters in the batch correction are the number of factors (k), the penalty parameter (lambda), and the clustering resolution. The number of factors sets the number of factors (consisting of shared and dataset-specific factors) used in factorizing the matrix. The penalty parameter sets the balance between factors shared across the batches and factors specific to the individual batches. The default setting of lambda=5.0 is usually used by the Macosko lab. Resolution=1.0 is used in the Louvain clustering of the shared neighbor factors that have been quantile normalized.


```{r eval = FALSE, batchcorrect_liger, filename = "R"}
ob.list <- list("celseq" = celseq, "celseq2" = celseq2, "fluidigmc1" = fluidigmc1, "smartseq2" = smartseq2)

# Create a LIGER object with raw counts data from each batch.
library(rliger)
data.liger <- createLiger(
  sapply(ob.list, function(data) data[['RNA']]@counts[, colnames(data)]), 
  remove.missing = FALSE
) 

# Normalize gene expression for each batch.
data.liger <- rliger::normalize(data.liger)

# Find variable genes for LIGER analysis.
data.liger <- selectGenes(data.liger, var.thresh = 0.1, do.plot = F)
print(length(data.liger@var.genes))
```



::: {.callout-question .icon .callout-note}

Scale the gene expression across the datasets. 

Why does LIGER not center the data? 

*Hint:* think about the use of non-negative matrix factorization and the constraints that this imposes.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = FALSE, batchcorrect_liger2, filename = "R"}
data.liger <- scaleNotCenter(data.liger)
```


:::

:::

Next, we will run the integrative non-negative matrix factorization. 

::: {.callout-question .icon .callout-note}

Use the `runIntegration` function to perform the integrative non-negative matrix factorization.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = FALSE, batchcorrect_liger3, filename = "R"}
data.liger <- runIntegration(data.liger) 
```


:::

What do matrices H, V, and W represent, and what are their dimensions?


```{r eval = FALSE, batchcorrect_liger4, filename = "R"}
dim(data.liger@H$celseq)
dim(data.liger@V$celseq)
dim(data.liger@W)
```


:::


Next, do clustering of cells in shared nearest factor space.

::: {.callout-question .icon .callout-note}

Do quantile normalization, cluster quantile normalized data


::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = FALSE, batchcorrect_liger5, filename = "R"}
data.liger <- quantileNorm(data.liger, resolution = 1) 
dim(data.liger@H.norm)
```


:::

What are the dimensions of H.norm. What does this represent? 

:::


Let's see what the liger data looks like mapped onto a UMAP visualization. 

::: {.callout-question .icon .callout-note}

Run UMAP on the quantile normalized data and visualize the clusters.

::: {.callout-answer .icon .callout-note collapse=true}


```{r eval = FALSE, batchcorrect_liger6, filename = "R"}
data.liger <- runUMAP(data.liger, n_neighbors = 15, min_dist = 0.5)
p <- plotByDatasetAndCluster(data.liger, return.plots = TRUE) 
print(p[[1]])
plot_grid(p[[1]], p[[2]])
```


:::

:::



```{r eval = FALSE, echo = FALSE, batchcorrect_liger7, filename = "R"}
# Let's look to see how the adjusted rand index changed compared to using no batch correction.
tech <- unlist(lapply(1:length(data.liger@H), function(x) { 
  rep(names(data.liger@H)[x], nrow(data.liger@H[[x]]))}))
clusters <- data.liger@clusters
ari <- data.frame("tech" = tech, "clusters" = clusters)
ari$tech <- plyr::mapvalues(ari$tech, from = c("celseq", "celseq2", "fluidigmc1", "smartseq2"), to = c(0, 1, 2, 3))
adj.rand.index(as.numeric(ari$tech), as.numeric(ari$clusters))

# Look at genes that are specific to a dataset and shared across datasets.
# Use the plotWordClouds function and choose 2 datasets.
pdf(paste0(writedir, "word_clouds.pdf"))
plotWordClouds(data.liger, dataset1 = "celseq2", dataset2 = "smartseq2")
dev.off()

# Look at factor loadings for each cell using plotFactors. 
pdf(paste0(writedir, "plot_factors.pdf"))
plotFactors(data.liger)
dev.off()

# Identify shared and batch-specific marker genes from liger factorization.
# Use the getFactorMarkers function and choose 2 datasets.
# Then plot some genes of interest using plotGene.
markers <- getFactorMarkers(data.liger, dataset1 = "celseq2", dataset2 = "smartseq2", num.genes = 10)
plotGene(data.liger, gene = "INS", pt.size = 1)
```


## Additional exploration

### Regressing out unwanted covariates 

Learn how to regress out different technical covariates (number of UMIs, number of genes, percent mitochondrial reads) by studying [Seurat's PBMC tutorial](https://satijalab.org/seurat/pbmc3k_tutorial.html) and the `ScaleData()` function.

### kBET

Within your RStudio session, install [k-nearest neighbour batch effect test](https://github.com/theislab/kBET) and learn how to use its functionality to quantify batch effects in the pancreatic data.

## Acknowledgements

This document builds off a tutorial from the [Seurat website](https://www.dropbox.com/s/aji4ielg8gc70vj/multiple_pancreas_workflow.R?dl=1) and a tutorial from the [LIGER website](http://htmlpreview.github.io/?https://github.com/welch-lab/liger/blob/master/vignettes/Integrating_multi_scRNA_data.html).

## Session info 


```{r eval = TRUE, echo = FALSE}
devtools::session_info()
```

